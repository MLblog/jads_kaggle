{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregating data per customer\n",
    "\n",
    "We need to predict the target at customer-level, i.e., we predict one value for each customer\n",
    "in the test set. Our data, however, contains a row for every site visit. One obvious way to deal\n",
    "with this discrepancy is to aggregate the visit data by customer, to obtain features on the\n",
    "customer-level.\n",
    "\n",
    "The _preprocessing.py_ file contains functions to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from preprocessing import keep_intersection_of_columns\n",
    "from aggregation import (\n",
    "    load_train_test_dataframes,\n",
    "    aggregate_data_per_customer,\n",
    ")\n",
    "\n",
    "data_dir = \"../data/\"\n",
    "train, test = load_train_test_dataframes(data_dir, nrows_train=50000, nrows_test=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Grab a coffee, you're train data will be aggregated in 5 minutes.\")\n",
    "aggregated_train = aggregate_data_per_customer(train)\n",
    "aggregated_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data should be close to what we need to start fitting models. We tried to keep as much information as possible, so from here it is of course still possible to remove features that seem unnecessary or do other dimensionality reduction. The good thing is that we don't have to do aggregation every time, so let's save the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Saving file, this takes a while. Like, a lot longer than you hope.\")\n",
    "aggregated_train.to_csv(os.path.join(data_dir, \"aggregated_train.csv\"), index=True)\n",
    "print(\"Train data saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat for test set\n",
    "aggregated_test = aggregate_data_per_customer(test)\n",
    "print(\"Saving test file...\")\n",
    "aggregated_test.to_csv(os.path.join(data_dir, \"aggregated_test.csv\"), index=True)\n",
    "print(\"All set and ready to start modeling!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our first attempt!\n",
    "Let's see if we can fit a model on this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if already saved:\n",
    "# aggregated_train = pd.read_csv(os.path.join(data_dir, \"aggregated_train.csv\"), dtype={\"fullVisitorId\": str})\n",
    "# aggregated_test = pd.read_csv(os.path.join(data_dir, \"aggregated_test.csv\"), dtype={\"fullVisitorId\": str})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that due to the one-hot encoding, the columns of train and test are not the same. For this experiment, only keep the intersection of columns. There are also other ways to deal with this (e.g., by mapping categories to external data), so we don't do this in the aggregation step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just for illustration, so let's keep it simple\n",
    "from sklearn import linear_model\n",
    "\n",
    "# create train and test sets and labels excluding visitor ID\n",
    "x_train, x_test = keep_intersection_of_columns(aggregated_train.reset_index(drop=True),\n",
    "                                               aggregated_test.reset_index(drop=True))\n",
    "y_train = np.log(aggregated_train.reset_index(drop=True)[\"target_sum\"]+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set NaNs to zero and fit linear model\n",
    "x_train = x_train.fillna(0)\n",
    "x_test = x_test.fillna(0)\n",
    "\n",
    "lm = linear_model.LinearRegression()\n",
    "lm.fit(x_train, y_train)\n",
    "r_squared = lm.score(x_train, y_train)\n",
    "print(\"The model has an R^2 of {}.\".format(r_squared))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict and create a submission\n",
    "predictions = lm.predict(x_test)\n",
    "submission = pd.concat([aggregated_test.reset_index()[\"fullVisitorId\"], pd.Series(predictions)], axis=1)\n",
    "submission.columns = [\"fullVisitorId\", \"PredictedLogRevenue\"]\n",
    "\n",
    "# set everything below $1 to zero\n",
    "submission[\"PredictedLogRevenue\"] = np.maximum(0, submission[\"PredictedLogRevenue\"])\n",
    "submission[\"PredictedLogRevenue\"][submission[\"PredictedLogRevenue\"]<1] = 0\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"first_submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
