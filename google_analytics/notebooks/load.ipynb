{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import datetime\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append('..')\n",
    "from preprocessing import load, process, preprocess_and_save\n",
    "from aggregation import ohe_explicit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data\n",
    "\n",
    "The file *preprocessing.py* contains function to load the JSON data, convert to Pandas DataFrames, and perform basic preprocessing (e.g., delete columns that are constant). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded file ../data/train.csv\n",
      "Shape is: (903653, 55)\n"
     ]
    }
   ],
   "source": [
    "train = load(\"../data/train.csv\")\n",
    "\n",
    "const_cols = [c for c in train.columns if train[c].nunique(dropna=False) == 1]\n",
    "train = train.drop(const_cols, axis=1)\n",
    "\n",
    "# Cast target\n",
    "train[\"transactionRevenue\"] = train[\"transactionRevenue\"].fillna(0).astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis: certain profiles should be naively assigned a zero predicted revenue\n",
    "\n",
    "Since the new problem description includes much less information at prediction time (no session info) it might be beneficial to only focus on visitors with a high probability to spend - and assign a zero prediction to everyone else.\n",
    "\n",
    "**Which profile is improbable enough to make a purchase, that it makes sense to make that prediction naively?**\n",
    "\n",
    "We think that visitors with a single visit that did not lead to a purchase during the training period (prior to December of the testing year) have a very high probability of not buying anything during December and January either. Let's test this assumption.\n",
    "\n",
    "Note that for now we only have data from August 2016 until August 2017. Therefore we test the assumption based on data from August 2016 until November 2016 (x_train) for December 2016 and January 2017 (y_train). \n",
    "When we reveice the new data, we can test it again for the period August 2016 until Oktober 15 2017 (x_train) for December 2017 and December 2018 (y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train[(train[\"date\"] < '2016-12-01')]\n",
    "y_train = train[(train[\"date\"] >= '2016-12-01') & (train[\"date\"] < '2017-02-01')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 263866 such visitors (out of 295432 found in our training set in total).\n"
     ]
    }
   ],
   "source": [
    "# Find people with a single visit during the training period\n",
    "count = x_train[[\"fullVisitorId\", \"transactionRevenue\"]].groupby(\"fullVisitorId\").count().reset_index()\n",
    "\n",
    "single_visit_ids = count[count[\"transactionRevenue\"] == 1][\"fullVisitorId\"]\n",
    "print(\"There are {} such visitors (out of {} found in our training set in total).\".format(len(single_visit_ids), len(count)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 263866 single visits, 1107 ended up in a purchase\n"
     ]
    }
   ],
   "source": [
    "# But maybe some of those guys actually bought something in that single visit.\n",
    "single_visits = x_train[x_train[\"fullVisitorId\"].isin(single_visit_ids)]\n",
    "num_purchases = len(single_visits[single_visits[\"transactionRevenue\"] > 0][\"transactionRevenue\"])\n",
    "print(\"Out of {} single visits, {} ended up in a purchase\".format(len(single_visit_ids), num_purchases))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will therefore choose to ignore 262759 users\n"
     ]
    }
   ],
   "source": [
    "to_ignore = set(single_visit_ids) - set(single_visits[single_visits[\"transactionRevenue\"] > 0][\"fullVisitorId\"])\n",
    "print(\"We will therefore choose to ignore {} users\".format(len(to_ignore)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is this assumption justified?\n",
    "\n",
    "How reliable is this assumption? Are these people that we choose to ignore indeed buying nothing? Let's find out.\n",
    "\n",
    "We now predicted zero for all visitors that visited once from August to November and bought nothing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We made 157 mistakes (0.06% of cases) leading to loss = 0.43796985063585375\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create a df containing all visitor that are ignored and their actual target\n",
    "actual_targets = pd.DataFrame()\n",
    "actual_targets['ignored'] = list(to_ignore)\n",
    "y_train_grouped = y_train[[\"fullVisitorId\", \"transactionRevenue\"]].groupby(\"fullVisitorId\", as_index=False).sum()\n",
    "actual_targets = pd.merge(actual_targets, y_train_grouped, how='left', left_on='ignored', right_on='fullVisitorId')\n",
    "actual_targets['transactionRevenue'] = actual_targets['transactionRevenue'].fillna(0).astype(float)\n",
    "\n",
    "actual_target = actual_targets[\"transactionRevenue\"].apply(lambda revenue: np.log(revenue + 1))\n",
    "\n",
    "predicted_target = [0] * len(to_ignore)\n",
    "    \n",
    "loss = np.sqrt(np.mean((predicted_target - actual_target)**2))\n",
    "num_mistakes = sum(actual_target > 0)\n",
    "\n",
    "print(\"We made {} mistakes ({:.2f}% of cases) leading to loss = {}\".format(num_mistakes, 100*num_mistakes/len(actual_target) ,loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "262759"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(actual_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is this small enough?\n",
    "\n",
    "We now mispredicted 157 out of 262759 people and a loss of 0.4380 in the log space. \n",
    "\n",
    "However we do not yet know what a predictive model would be able to predict (without any session information of course). If a model would be able to do better, then its of course a bad idea to ignore these guys. If the predictive model fails, then its a good idea to ignore them.\n",
    "\n",
    "As a next step, we are checking the visit date in the x_train for the visitors for which we made a mistake. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1b3a123b908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mistakes = actual_targets[actual_targets['transactionRevenue'] > 0]\n",
    "visit_date_mistakes = x_train[x_train['fullVisitorId'].isin(mistakes['ignored'])]['date']\n",
    "\n",
    "x = visit_date_mistakes.values\n",
    "plt.hist(x, normed=False, bins=5)\n",
    "plt.ylabel('Number of mistakes')\n",
    "plt.xlabel('Date of the visit in x_train')\n",
    "plt.rcParams[\"figure.figsize\"] = (10,4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the visit dates of vistors for which we made a mistakes is highly skewed to the right. Which indicates that people that are visiting once and are not buying in the end of November 2016 are more likely to buy in December and January. \n",
    "Therefore it could be beneficial only remove people that visited once before a specific month and did not buy anything, instead of removing all people who visited once and did not buy anything. \n",
    "\n",
    "Suggestion:\n",
    "Can we also remove people from the dataset that never bought and did not visit the webshop a couple (to be defined) of months before y_train?\n",
    "\n",
    "**To be continued!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this if you need to recreate the initial dataset\n",
    "#preprocess_and_save(\"../data\", nrows_train=100000, nrows_test=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categoricals with many values\n",
    "\n",
    "There are a number of categorical features with many different values. This is an issue, specifically in the cases where those categorical features are not ordinal, and therefore label encoding them does not make sense. The only choice we are left with, is OHE. However naively performing this step would add hundreds of columns for each original categorical feature - in the end yielding potentially thousands of super sparse features. What I would like to explore, is whether there exist **specific values** with predictive value significantly higher than average. For example, looking at the particular country might be a weak predictor. However there might be 5 specific countries with a huge revenue deviation from the average (and enough samples to consider this discrepancy statistically significant)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = load(\"../data/train.csv\")\n",
    "test = load(\"../data/test.csv\", nrows=10000)\n",
    "train, test = process(train, test)\n",
    "\n",
    "countries = train['country']\n",
    "print(\"There are {} different countries in our dataset\".format(len(countries.unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregations = {'target':['mean', 'count']}\n",
    "\n",
    "countries = train[[\"country\", \"target\"]].groupby(\"country\", as_index=False).agg(aggregations)\n",
    "countries.columns = [\"country\", \"targetMean\", \"occurenceCount\"]\n",
    "\n",
    "# Let's focus only on countries with multiple records to preserve some statistical significance\n",
    "keep = 10\n",
    "usual_countries = countries.sort_values(\"occurenceCount\", ascending=False).head(keep)\n",
    "\n",
    "global_average = train[\"target\"].mean()\n",
    "usual_countries[\"deviation\"] = usual_countries[\"targetMean\"] - global_average\n",
    "usual_countries.plot.bar(x=\"country\", y=\"deviation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USA seems quite different\n",
    "\n",
    "What we can find here is that USA is very different to any other country with significant sample count. What we can do with this information? We instead of using OHE to code every country in our dataset, we can probably get away with a single boolean column: **is this record coming from the USA?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = train['city']\n",
    "print(\"There are {} different cities in our dataset\".format(len(cities.unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregations = {'target':['mean', 'count']}\n",
    "\n",
    "cities = train[[\"city\", \"target\"]].groupby(\"city\", as_index=False).agg(aggregations)\n",
    "cities.columns = [\"city\", \"targetMean\", \"occurenceCount\"]\n",
    "\n",
    "# Let's focus only on countries with multiple records to preserve some statistical significance\n",
    "keep = 10\n",
    "usual_cities = cities.sort_values(\"occurenceCount\", ascending=False).head(keep)\n",
    "\n",
    "global_average = train[\"target\"].mean()\n",
    "usual_cities[\"deviation\"] = usual_cities[\"targetMean\"] - global_average\n",
    "usual_cities.plot.bar(x=\"city\", y=\"deviation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What about the cities?\n",
    "\n",
    "Here we can see some pretty strong deviations. However we need to note that the top ones come from US cities, so part of the variance these cities explain, is already included in the information that they belong to the USA. However their deviation is considerably higher than that of USA alone (1.0 vs 0.3) so including those columns might still be beneficial. The deviation we see is actually very distorted because of the USA outlier. Perhaps it would make more sense to only focus on the deviation from the average of non-USA cities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_not_us = train[train['country'] != \"United States\"]\n",
    "train_us = train[train['country'] == \"United States\"]\n",
    "\n",
    "outside_us_avg = train_not_us['target'].mean()\n",
    "us_avg = train_us[\"target\"].mean()\n",
    "\n",
    "print(\"Average in US: {}\\nAverage outside US: {}\".format(us_avg, outside_us_avg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's then repeat out analysis but this time separatly for the pieces of data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregations = {'target':['mean', 'count']}\n",
    "\n",
    "# US case\n",
    "def city_deviation(df, title=\"Deviation per city\"):\n",
    "    cities = df[[\"city\", \"target\"]].groupby(\"city\", as_index=False).agg(aggregations)\n",
    "    cities.columns = [\"city\", \"targetMean\", \"occurenceCount\"]\n",
    "\n",
    "    # Let's focus only on countries with multiple records to preserve some statistical significance\n",
    "    keep = 10\n",
    "    usual_cities = cities.sort_values(\"occurenceCount\", ascending=False).head(keep)\n",
    "\n",
    "    global_average = df[\"target\"].mean()\n",
    "    usual_cities[\"deviation\"] = usual_cities[\"targetMean\"] - global_average\n",
    "    ax = usual_cities.plot.bar(x=\"city\", y=\"deviation\", title=title, rot=45, legend=False)\n",
    "    ax.set_xlabel(\"City\")\n",
    "    ax.set_ylabel(\"Deviation\")\n",
    "    \n",
    "city_deviation(train_us, title=\"Deviation from the mean - US\")\n",
    "city_deviation(train_not_us, title=\"Deviation from the mean - Rest of the world\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Much better!\n",
    "\n",
    "Now we can clearly see what information should be included besides the country (or to be exact, whether or not the country is the US). For example it makes no sense to include Los Angeles or Mountain View even though they deviate from the global average, because all this deviation is explained by the fact that they exist in the US! Instead we should include Chicago, New York, Austin, Seattle and maybe Palo Alto. And as we can see the deviations are much smaller outside the US, with the exception of Toronto which MUST be included.\n",
    "\n",
    "### Food for thought\n",
    "It makes sense that deviations outside the US are smaller because the target itself is considerable lower. Perhaps we should look at relative deviations instead?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = ohe_explicit(train)\n",
    "check.head()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
