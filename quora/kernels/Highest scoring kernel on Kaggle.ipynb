{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Highest scoring kernel on Kaggle\n",
    "\n",
    "This notebooks reproduces the results of our highest scoring kernel in the Quora competition on the public leaderboard.\n",
    "The most important elements of this submission are:\n",
    "- Only a sequence model is used\n",
    "- The average of the Glove and Para embeddings are taken\n",
    "- An Attention and Capsule layer is used in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import sys\n",
    "sys.path.append(\"../..\") # Append source directory to our Python path\n",
    "\n",
    "from common.nlp.sequence_preprocessing import preprocess_text_for_dl, fit_tokenizer, tokenize_and_pad\n",
    "from common.nlp.load_embeddings import load_word_embedding, load_word2vec, create_embedding_matrix\n",
    "from quora.sequence_models import cross_validate_and_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load datasets and initialize parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data with right data types and preprocess\n",
    "dtypes = {\"qid\": str, \"question_text\": str, \"target\": int}\n",
    "training = pd.read_csv(\"../data/train.csv\", dtype=dtypes)\n",
    "testing = pd.read_csv(\"../data/test.csv\", dtype=dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 75 # maximum number of words in a sentence/document\n",
    "\n",
    "# Initialize WORD_MAP\n",
    "WORD_MAP = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\",\n",
    "           \"could've\": \"could have\", \"couldn't\": \"could not\", \"didn't\": \"did not\",\n",
    "           \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\",\n",
    "           \"haven't\": \"have not\", \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\",\n",
    "           \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\n",
    "           \"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\",\n",
    "           \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\",\n",
    "           \"it'd\": \"it would\", \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\n",
    "           \"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\",\n",
    "           \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\",\n",
    "           \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\",\n",
    "           \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\",\n",
    "           \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\",\n",
    "           \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\",\n",
    "           \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\",\n",
    "           \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\", \"this's\": \"this is\",\n",
    "           \"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\",\n",
    "           \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\",\n",
    "           \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\",\n",
    "           \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\",\n",
    "           \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",  \"what's\": \"what is\",\n",
    "           \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \n",
    "           \"y'all'd\": \"you all would\", \"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "           \"you're\": \"you are\", \"you've\": \"you have\", 'hasnt': 'has not',\n",
    "            'colour':'color', 'centre':'center', 'didnt':'did not', 'doesnt':'does not',\n",
    "            'isnt':'is not', 'shouldnt':'should not', 'favourite':'favorite','travelling':'traveling',\n",
    "            'counselling':'counseling', 'theatre':'theater', 'cancelled':'canceled', 'labour':'labor',\n",
    "            'organisation':'organization', 'wwii':'world war 2', 'citicise':'criticize', 'instagram': 'social medium',\n",
    "            'whatsapp': 'social medium', 'snapchat': 'social medium', 'behaviour': 'behavior', 'realise': 'realize',\n",
    "            'defence': 'defense', 'programme': 'program', 'upvotes': 'votes', 'grey': 'gray', 'btech': 'bachelor of technology',\n",
    "            'mtech': 'master of technology', 'cryptocurrency': 'digital currency', 'cryptocurrencies': 'digital currencies', 'bitcoin': 'digital currency',\n",
    "            'bitcoins': 'digital currency', 'Bitcoin': 'digital currency', 'Btech': 'Bachelor of Technology', 'Isnt': 'Is not',\n",
    "            'Snapchat': 'social medium', 'doesnt': 'does not', 'programmr': 'programmer', 'programr': 'programmer',\n",
    "            'didnt': 'did not', 'blockchain': 'software technology', 'Shouldnt': 'Should not', 'Doesnt': 'Does not', 'isnt': 'is not',\n",
    "            'programrs': 'programmers', 'currencys': 'currencies', 'honours': 'honors', 'upvote': 'vote', 'learnt': 'learned', 'licence': 'license',\n",
    "            'Ethereum': 'digital currency', 'Whatis': 'What is', 'bcom': 'bachelor of commerce', 'aluminium': 'aluminum', 'favour': 'favor',\n",
    "            'Pinterest': 'social medium', 'cheque': 'check', 'judgement': 'judgment', 'modelling': 'modeling', 'Xiaomi': 'phone', 'Coursera': 'online platform',\n",
    "            'Quora': 'online platform', 'OnePlus': 'phone', 'wasnt': 'was not', 'recognise': 'recognize', \n",
    "            'organisation': 'organization', 'organisations': 'organizations', 'colour': 'color', 'colours': 'colors', 'coloured': 'colored',\n",
    "            'Fortnite': 'video game', 'centres': 'centers', \n",
    "            'Quorans': 'people', \"Quoras\": \"online platform's\", 'jewellery': 'jewelry store', 'Lyft': 'ride sharing platform',\n",
    "            'Didnt': 'Did not', 'practise': 'practice', 'vape': 'smoke', 'WeChat': 'social medium', 'analyse': 'analyze', 'travelled': 'traveled',\n",
    "            'recognised': 'recognized', 'GDPR': 'privacy bill', 'neighbours': 'neighbors', 'demonetisation': 'demonetization', 'programmes': 'programs',\n",
    "            'Blockchain': 'software technology', 'Nodejs': 'software technology', 'Coinbase': 'online platform', 'litre': 'liter', 'upvoted': 'voted',\n",
    "            'sulphuric': 'sulfuric', 'Musks': \"Musk's\", 'neighbour': 'neighbor', 'selfies': 'photos', 'tyres': 'tires', 'ICOs': 'initial coin offerings',\n",
    "            'Wasnt': 'Was not', 'realised': 'realized', 'specialisation': 'specialization', 'ethereum': 'digital currency', 'tyre': 'tire',\n",
    "            'organised': 'organized', 'traveller': 'traveler', 'downvote': 'vote against', 'selfie': 'photo', 'Udacity': 'online platform', 'offence': 'offense',\n",
    "            'litres': 'liters', 'vapour': 'vapor', 'Qoura': 'online platform', 'fibre': 'fiber', 'aeroplane': 'airplane', 'laymans': 'laymen', 'humour': 'humor',\n",
    "            'utilise': 'utilize', 'civilisation': 'civilization', 'sulphur': 'sulfur', 'archaeology': 'archeology', 'masterbate': 'masturbate', 'Upwork': 'online platform',\n",
    "            'neurotypicals': 'non-autistic people', 'criticise': 'criticize', 'organise': 'organize', 'labelled': 'labeled', 'cosx': 'cosine x',\n",
    "            'judgemental': 'judgmental', 'dreamt': 'dreamed', 'Xamarin': 'medicin', 'MOOCs': 'online classes', 'emojis': 'smileys', 'Unacademy': 'online platform',\n",
    "            'neighbouring': 'neighboring', 'cancelling': 'canceling', 'numericals': 'numerical', 'honour': 'honor', 'globalisation': 'globalization',\n",
    "            'practising': 'practicing', 'WooCommerce': 'software technology', 'behavioural': 'behavioral', 'masterbation': 'masturbation', 'AngularJS': 'software technology',\n",
    "            'wwwyoutubecom': 'online platform', 'Terroristan': 'terrorist Pakistan', 'terroristan': 'terrorist Pakistan', \n",
    "            'BIMARU': 'Bihar, Madhya Pradesh, Rajasthan, Uttar Pradesh', 'Hinduphobic': 'Hindu phobic', 'hinduphobic': 'Hindu phobic', 'Hinduphobia': 'Hindu phobic', \n",
    "            'hinduphobia': 'Hindu phobic', 'Babchenko': 'Arkady Arkadyevich Babchenko faked death', 'Boshniaks': 'Bosniaks',\n",
    "            'Dravidanadu': 'Dravida Nadu', 'mysoginists': 'misogynists', 'MGTOWS': 'Men Going Their Own Way', 'unsincere': 'insincere',\n",
    "            'meninism': 'male feminism', 'jewplicate': 'jewish replicate', 'unoin': 'Union', 'daesh': 'Islamic State of Iraq and the Levant',\n",
    "            'Kalergi': 'Coudenhove-Kalergi', 'Bhakts': 'Bhakt', 'bhakts': 'Bhakt', 'Tambrahms': 'Tamil Brahmin', 'Pahul': 'Amrit Sanskar',\n",
    "            'SJW': 'social justice warrior', 'SJWs': 'social justice warrior', 'incel': ' involuntary celibates', 'incels': ' involuntary celibates',\n",
    "            'emiratis': 'Emiratis', 'weatern': 'western', 'westernise': 'westernize', 'Pizzagate': 'Pizzagate conspiracy theory', 'naïve': 'naive',\n",
    "            'Skripal': 'Sergei Skripal', 'Remainers': 'British remainer', 'remainers': 'British remainer', 'bremainer': 'British remainer',\n",
    "            'antibrahmin': 'anti Brahminism', 'HYPSM': 'Harvard, Yale, Princeton, Stanford, MIT', 'HYPS': 'Harvard, Yale, Princeton, Stanford',\n",
    "            'kompromat': 'compromising material', 'Tharki': 'pervert', 'tharki': 'pervert', 'mastuburate': 'masturbate', 'Zoë': 'Zoe',\n",
    "            'indans': 'Indian', 'xender': 'gender', 'Naxali ': 'Naxalite ', 'Naxalities': 'Naxalites', 'Bathla': 'Namit Bathla', \n",
    "            'Mewani': 'Indian politician Jignesh Mevani', 'clichéd': 'cliche', 'cliché': 'cliche', 'clichés': 'cliche', 'Wjy': 'Why',\n",
    "            'Fadnavis': 'Indian politician Devendra Fadnavis', 'Awadesh': 'Indian engineer Awdhesh Singh', 'Awdhesh': 'Indian engineer Awdhesh Singh',\n",
    "            'Khalistanis': 'Sikh separatist movement', 'madheshi': 'Madheshi', 'BNBR': 'Be Nice, Be Respectful', 'Bolsonaro': 'Jair Bolsonaro',\n",
    "            'XXXTentacion': 'Tentacion', 'Padmavat': 'Indian Movie Padmaavat', 'Žižek': 'Slovenian philosopher Slavoj Žižek', 'Adityanath': 'Indian monk Yogi Adityanath',\n",
    "            'Brexit': 'British Exit', 'Brexiter': 'British Exit supporter', 'Brexiters': 'British Exit supporters', 'Brexiteer': 'British Exit supporter',\n",
    "            'Brexiteers': 'British Exit supporters', 'Brexiting': 'British Exit', 'Brexitosis': 'British Exit disorder', 'brexit': 'British Exit',\n",
    "            'brexiters': 'British Exit supporters', 'jallikattu': 'Jallikattu', 'fortnite': 'Fortnite ', 'Swachh': 'Swachh Bharat mission campaign ',\n",
    "            'Quorans': 'Quoran', 'Qoura ': 'Quora ', 'quoras': 'Quora', 'Quroa': 'Quora', 'QUORA': 'Quora', 'narcissit': 'narcissist', 'Doklam': 'Tibet',\n",
    "            'Drumpf': 'Donald Trump fool', 'Drumpfs': 'Donald Trump fools', 'Strzok': 'Hillary Clinton scandal', 'rohingya': 'Rohingya ',\n",
    "            'wumao': 'cheap Chinese stuff', 'wumaos': 'cheap Chinese stuff', 'Sanghis': 'Sanghi', 'Tamilans': 'Tamils', 'biharis': 'Biharis',\n",
    "            'Rejuvalex': 'hair growth formula', 'Feku': 'Fake', 'deplorables': 'deplorable', 'muhajirs': 'Muslim immigrant', 'Gujratis': 'Gujarati',\n",
    "            'Chutiya': 'Fucker', 'Chutiyas': 'Fucker', 'thighing': 'masturbate', '卐': 'Nazi Germany', 'Pribumi': 'Native Indonesian',\n",
    "            'Gurmehar': 'Gurmehar Kaur Indian student activist', 'Novichok': 'Soviet Union agents', 'Khazari': 'Khazars', 'Demonetization': 'demonetization',\n",
    "            'demonetisation': 'demonetization', 'demonitisation': 'demonetization', 'demonitization': 'demonetization', 'demonetisation': 'demonetization',\n",
    "            'cryptocurrencies': 'cryptocurrency', 'Hindians': 'North Indian who hate British', 'vaxxer': 'vocal nationalist ', 'remoaner': 'remainer ',\n",
    "            'bremoaner': 'British remainer ', 'Jewism': 'Judaism', 'Eroupian': 'European', 'WMAF': 'White male married Asian female', 'moeslim': 'Muslim',\n",
    "            'cishet': 'cisgender and heterosexual person', 'Eurocentric': 'Eurocentrism ', 'Jewdar': 'Jew dar', 'Asifa': 'abduction, rape, murder case ',\n",
    "            'marathis': 'Marathi', 'Trumpanzees': 'Trump chimpanzee fool', 'Crimean': 'Crimea people ', 'atrracted': 'attract', \n",
    "            'LGBT': 'lesbian, gay, bisexual, transgender', 'Boshniak': 'Bosniaks ', 'Myeshia': 'widow of Green Beret killed in Niger', 'demcoratic': 'Democratic',\n",
    "            'raaping': 'rape', 'Dönmeh': 'Islam', 'feminazism': 'feminism nazi', 'langague': 'language', 'Hongkongese': 'HongKong people',\n",
    "            'hongkongese': 'HongKong people', 'Kashmirians': 'Kashmirian', 'Chodu': 'fucker', 'penish': 'penis', 'micropenis': 'tiny penis', \n",
    "            'Madridiots': 'Real Madrid idiot supporters', 'Ambedkarite': 'Dalit Buddhist movement ', 'ReleaseTheMemo': 'cry for the right and Trump supporters',\n",
    "            'harrase': 'harass', 'Barracoon': 'Black slave', 'Castrater': 'castration', 'castrater': 'castration', 'Rapistan': 'Pakistan rapist', \n",
    "            'rapistan': 'Pakistan rapist', 'Turkified': 'Turkification', 'turkified': 'Turkification', 'Dumbassistan': 'dumb ass Pakistan',\n",
    "            'facetards': 'Facebook retards', 'rapefugees': 'rapist refugee', 'superficious': 'superficial', 'colour': 'color', 'centre': 'center',\n",
    "            'favourite': 'favorite', 'travelling': 'traveling', 'counselling': 'counseling', 'theatre': 'theater', 'cancelled': 'canceled', \n",
    "            'labour': 'labor', 'organisation': 'organization', 'wwii': 'world war 2', 'citicise': 'criticize', 'youtu ': 'youtube ', 'sallary': 'salary',\n",
    "            'Whta': 'What', 'narcisist': 'narcissist', 'narcissit': 'narcissist', 'howdo': 'how do', 'whatare': 'what are', 'howcan': 'how can',\n",
    "            'howmuch': 'how much', 'howmany': 'how many', 'whydo': 'why do', 'doI': 'do I', 'theBest': 'the best', 'howdoes': 'how does', \n",
    "            'mastrubation': 'masturbation', 'mastrubate': 'masturbate', 'mastrubating': 'masturbating', 'pennis': 'penis', 'Etherium': 'Ethereum',\n",
    "            'bigdata': 'big data', '2k17': '2017', '2k18': '2018', 'qouta': 'quota', 'exboyfriend': 'ex boyfriend', 'airhostess': 'air hostess',\n",
    "            'whst': 'what', 'watsapp': 'whatsapp', 'bodyshame': 'body shaming', 'bodyshoppers': 'body shopping', 'bodycams': 'body cams',\n",
    "            'Cananybody': 'Can any body', 'deadbody': 'dead body', 'deaddict': 'de addict', 'Northindian': 'North Indian ', 'northindian': 'north Indian ',\n",
    "            'northkorea': 'North Korea', 'Whykorean': 'Why Korean', 'koreaboo': 'Korea boo ', 'Brexshit': 'British Exit bullshit', 'shithole': 'shithole ',\n",
    "            'shitpost': 'shit post', 'shitslam': 'shit Islam', 'shitlords': 'shit lords', 'Fck': 'Fuck', 'fck': 'fuck', 'Clickbait': 'click bait ',\n",
    "            'clickbait': 'click bait ', 'mailbait': 'mail bait', 'healhtcare': 'healthcare', 'trollbots': 'troll bots', 'trollled': 'trolled',\n",
    "            'trollimg': 'trolling', 'cybertrolling': 'cyber trolling', 'sickular': 'India sick secular ', 'suckimg': 'sucking', 'Idiotism': 'idiotism',\n",
    "            'Niggerism': 'Nigger', 'Niggeriah': 'Nigger'}\n",
    "\n",
    "# Initialize filepaths to embeddings\n",
    "EMBEDDING_FILE_GOOGLE = '../data/embeddings/GoogleNews-vectors-negative300/GoogleNews-vectors-negative300.bin'\n",
    "EMBEDDING_FILE_GLOVE = '../data/embeddings/glove.840B.300d/glove.840B.300d.txt'\n",
    "EMBEDDING_FILE_PARA = '../data/embeddings/paragram_300_sl999/paragram_300_sl999.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare data for using sequence models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Y = training[\"target\"].copy().values\n",
    "train, test = preprocess_text_for_dl(training.copy(), testing.copy(), puncts_ignore='/-', puncts_retain='&',\n",
    "                                     word_map=WORD_MAP, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete data to prevent for having memory errors\n",
    "del training, testing\n",
    "gc.collect()\n",
    "print('Preprocessing is done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Tokenize text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = fit_tokenizer(train, test, text_col=\"question_text\")\n",
    "train_X, test_X = tokenize_and_pad(tokenizer, train, test, text_col=\"question_text\", id_col=\"qid\", max_words=max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete data to prevent for having memory errors\n",
    "del train, test\n",
    "gc.collect()\n",
    "print('Tokenization is done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load embeddings\n",
    "Note that you can only use 2 out of 3 embeddings. Otherwise you will get a MemoryError."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load google (word2vec) embedding\n",
    "embedding_dict_google = load_word2vec(EMBEDDING_FILE_GOOGLE, return_as_dict=True)\n",
    "\n",
    "# Load other embeddings \n",
    "embedding_dict_para = load_word_embedding(EMBEDDING_FILE_PARA)\n",
    "embedding_dict_glove = load_word_embedding(EMBEDDING_FILE_GLOVE)\n",
    "\n",
    "# Create embeddings matrices and delete data to prevent for having memory errors\n",
    "embedding_matrix_google = create_embedding_matrix(tokenizer.word_index, embedding_dict_google)\n",
    "del embedding_dict_google\n",
    "gc.collect()\n",
    "print('Google embeddings are loaded!')\n",
    "\n",
    "embedding_matrix_para = create_embedding_matrix(tokenizer.word_index, embedding_dict_para)\n",
    "del embedding_dict_para\n",
    "gc.collect()\n",
    "print('Para embeddings are loaded!')\n",
    "\n",
    "embedding_matrix_glove = create_embedding_matrix(tokenizer.word_index, embedding_dict_glove)\n",
    "del embedding_dict_glove\n",
    "gc.collect()\n",
    "print('Glove embeddings are loaded!')\n",
    "\n",
    "# Create average weights\n",
    "embedding_matrix = np.mean((embedding_matrix_para, embedding_matrix_glove), axis=0)\n",
    "# Delete only the matrices that you loaded\n",
    "del embedding_matrix_glove, embedding_matrix_para, embedding_matrix_google \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#embedding_matrix = pd.read_pickle('embedding.pkl').values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create model and make a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "predictions = cross_validate_and_predict(train_X.values, train_Y, test_X.values, embedding_matrix, tokenizer.word_index, max_words, folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\"qid\": test_X.reset_index()[\"qid\"].values,\n",
    "                           \"prediction\": np.array(predictions, dtype=int)})\n",
    "submission.to_csv(\"submission_fullscript.csv\", index=False)\n",
    "print(\"Submission file save to current working directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
