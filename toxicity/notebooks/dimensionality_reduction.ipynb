{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality Reduction\n",
    "\n",
    "In this notebook we will explore how [gensim](https://github.com/RaRe-Technologies/gensim) can be used within a supervised machine learning context. Concretely, we can use the topic modeling tools included in the package to reduce the dimensionality\n",
    "of our (extremely sparse and wide) input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\") # Append source directory to our Python path\n",
    "\n",
    "from predictor import Predictor\n",
    "from linear_predictor import LogisticPredictor\n",
    "from preprocessing import *\n",
    "from utils import *\n",
    "\n",
    "DATA_ROOT = \"../data/\"\n",
    "\n",
    "train = pd.read_csv(\"../data/train.csv\")\n",
    "test = pd.read_csv(\"../data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract the true labels needed for training\n",
    "train_ys = {tag: train[tag].values for tag in TAGS}\n",
    "\n",
    "# Extract the test set ids needed for submitting\n",
    "ids = test['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the dimensionality reduction algorithms\n",
    "\n",
    "This will take a lot of time to run (around 20 minutes total on my machine). This is because the algorithms comprises of \n",
    "several computationally expensive steps:\n",
    "\n",
    "1. Tokenize text.\n",
    "2. Create the train and test corpora.\n",
    "3. Get the TFIDF sparse representations.\n",
    "4. Apply dimensionality reduction using LSA or LDA both of which are optimized but still demanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x = gensim_preprocess(train, test, model_type='lsi', num_topics=500, report_progress=True, data_dir=DATA_ROOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feeding the reduced input to sklearn\n",
    "\n",
    "Let's how our reduced input does using an (untuned) classifier from `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a logistic regression classifier.\n",
    "lr_params = {\"C\": 4, \"dual\": True}\n",
    "predictor = LogisticPredictor(**lr_params)\n",
    "\n",
    "# We are currently supporting 3 evaluation methods, stratified CV, random CV and split. Lets check them.\n",
    "stratified_cv_loss = predictor.evaluate(train_x, train_ys, method='stratified_CV')\n",
    "cv_loss = predictor.evaluate(train_x, train_ys, method='CV')\n",
    "split_loss = predictor.evaluate(train_x, train_ys, method='split')\n",
    "\n",
    "print(\"CV Stratified CV log loss: {}\\nCV log loss: {}\\nSplit CV log loss: {}\".format(stratified_cv_loss, cv_loss, split_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a submission \n",
    "\n",
    "Let's use our classifier to create a sample submittion and submit to [kaggle](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/submit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "create_submission(predictor, train_x, train_ys, test_x, ids, '../submissions/using_lsi.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "We could improve this pipeline by carefully tuning the dimensionality reduction steps (trying another `gensim.model`) and a stronger classifier (perhaps `XGBoost`?)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
