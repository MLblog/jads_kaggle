{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer learning \n",
    "\n",
    "In this notebook, I will use Transfer learning in our problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras import applications\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import  Model \n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras import backend as k \n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I copy $\\textbf{10%}$ of the image to a new folder and this will be my new training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = \"../data/sample_new/train\"\n",
    "validation_data_dir = \"../data/validation\"\n",
    "nb_train_samples = sum([len(files) for r, d, files in os.walk(train_data_dir)])\n",
    "nb_validation_samples = sum([len(files) for r, d, files in os.walk(validation_data_dir)])\n",
    "NUM_CLASSES = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the images should be resized. We will first find the smallest resolution in our datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smallest_train= None\n",
    "for dir_path, _, files in os.walk(train_data_dir):\n",
    "        for name in files:\n",
    "            temp_name = os.path.join(dir_path, name)\n",
    "            temp_shape = np.shape(np.array(Image.open(temp_name)))\n",
    "            if smallest_train == None:\n",
    "                smallest_train = temp_shape\n",
    "            elif temp_shape<smallest_train:\n",
    "                smallest_train = temp_shape\n",
    "            else:\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smallest_val = None\n",
    "for dir_path, _, files in os.walk(validation_data_dir):\n",
    "        for name in files:\n",
    "            temp_name = os.path.join(dir_path, name)\n",
    "            temp_shape = np.shape(np.array(Image.open(temp_name)))\n",
    "            if smallest_val == None:\n",
    "                smallest_val = temp_shape\n",
    "            elif temp_shape<smallest_val:\n",
    "                smallest_val = temp_shape\n",
    "            else:\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smallest = min(smallest_train, smallest_val)\n",
    "img_width, img_height = smallest[0], smallest[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the ResNet50 as model and we will fine-tune the fully connected last layer of pre-trained network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = applications.resnet50.ResNet50(include_top=False, weights='imagenet', input_tensor=None, input_shape = (img_width, img_height, 3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look to some of the parameters:\n",
    "1. The `weights='imagenet'` parameter will load the final weights after the model trained. \n",
    "2. The `include_top=False` parameter instantiates the model without its fully connected layers.\n",
    "\n",
    "Those layers somehow \"translates\" (I dunno if this the most correct word but you got my point) the convolutional information into the correct classes. Since ImageNet has 1000 different classes and our dataset 128 we donâ€™t need any of the information in these dense layers. Instead, we will train new dense layers, the last one having 128 nodes and a softmax activation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze the layers which you don't want to train. Here I am freezing all the layers\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # add a global spatial average pooling layer\n",
    "x = model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# let's add a fully-connected layer\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "# and a logistic layer \n",
    "predictions = Dense(NUM_CLASSES, activation='softmax')(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the full network so we can train on it\n",
    "transfer_model = Model(input=model.input, output=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INIT_LR = 5e-3  # initial learning rate\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 1\n",
    "\n",
    "# prepare model for fitting (loss, optimizer, etc)\n",
    "transfer_model.compile(\n",
    "    loss='categorical_crossentropy',  \n",
    "    optimizer=keras.optimizers.adamax(lr=INIT_LR),  \n",
    "    metrics=['accuracy']  \n",
    ")\n",
    "\n",
    "# scheduler of learning rate (decay with epochs)\n",
    "def lr_scheduler(epoch):\n",
    "    return INIT_LR * 0.9 ** epoch\n",
    "\n",
    "# callback for printing of actual learning rate used by optimizer\n",
    "class LrHistory(keras.callbacks.Callback):\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        print(\"Learning rate:\", k.get_value(transfer_model.optimizer.lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will rescale our images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "validation_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "train_data_dir,\n",
    "target_size = (img_width, img_height),\n",
    "batch_size = BATCH_SIZE,\n",
    "shuffle = True,\n",
    "class_mode = \"categorical\")\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "validation_data_dir,\n",
    "batch_size = BATCH_SIZE,\n",
    "target_size = (img_width, img_height),\n",
    "shuffle = True,\n",
    "class_mode = \"categorical\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And we will fine tune it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train the model \n",
    "transfer_model.fit_generator(\n",
    "train_generator,\n",
    "steps_per_epoch= nb_train_samples//BATCH_SIZE,\n",
    "epochs = EPOCHS,\n",
    "validation_data = validation_generator,\n",
    "validation_steps = nb_validation_samples//BATCH_SIZE,\n",
    "callbacks=[keras.callbacks.LearningRateScheduler(lr_scheduler), \n",
    "               LrHistory()],\n",
    "verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Using the `10%` of the data I achieve an accuracy of `~49%`. However, it took around 5 hours to complete just one epoch."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle_env",
   "language": "python",
   "name": "kaggle_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
