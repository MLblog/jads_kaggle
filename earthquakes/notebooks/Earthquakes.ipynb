{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pd.options.display.precision = 15\n",
    "data_dir = \"../data\"\n",
    "plt.style.use(\"dark_background\") # uncomment if using light jupyter theme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(os.path.join(data_dir, \"train.csv\"),\n",
    "                    dtype={\"acoustic_data\": np.int16, \"time_to_failure\": np.float64})\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"We have {:,} rows and {} columns.\".format(train.shape[0], train.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save the column names as variables for convenience:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xcol = \"acoustic_data\"\n",
    "ycol = \"time_to_failure\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test data has a different structure: there is a separate CSV for each segment. Let's look at a couple of them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the segment ids from the sample submission file\n",
    "sample_submission = pd.read_csv(os.path.join(data_dir, \"sample_submission.csv\"), index_col=\"seg_id\")\n",
    "x_test = pd.DataFrame(columns=[xcol], dtype=np.float64, index=sample_submission.index)\n",
    "\n",
    "# load first 10 segments\n",
    "for seg_id in x_test.index[0:10]:\n",
    "    segment = pd.read_csv(os.path.join(data_dir, \"test\", seg_id + \".csv\"))\n",
    "    print(\"shape: {}\".format(segment.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test data consists of segments of 150,000 observations each."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. EDA\n",
    "\n",
    "## 1.1. High level stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is centered around 4 or 5, but has big outlier values (high as well as low). Let's look at this closer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of earthquakes is {}\".format(np.sum(train[ycol] - train[ycol].shift(1) > 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Distributions\n",
    "\n",
    "Let's see where our signal values are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[xcol].hist(bins=np.arange(-20, 30, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They show a nice Gaussian distribution in general, but note that we cut off the outliers in this plot. Plot those separately:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_quantiles(data, q, ax):\n",
    "    y = np.quantile(data, q=q)\n",
    "    return ax.plot(q, y)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "x1 = np.arange(0.95, 1.0, 0.005)\n",
    "x2 = np.arange(0.95, 0.995, 0.005)\n",
    "axes[0] = plot_quantiles(train[xcol].values, x1, axes[0])\n",
    "axes[1] = plot_quantiles(train[xcol].values, x2, axes[1])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The highest values are way, way higher than all others: as seen in some kernels, these happen right before an earthquake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[ycol].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Creating training data similar to test data\n",
    "\n",
    "Our training data is one big, continuous sequence of observations, while ttthe test data consists of smaller segments of 150,000 observations each. In order to train in the same way that we need to predict, we should make the datasets more similar. Firstly, we need to create sequences of train data similar to the test sequences. This can be done in multiple ways:\n",
    "1. The easiest way to do this is simply to cut the training data in pieces of 150,000 sequential observations, i.e., take values 0 to 149999, 150000 to 299999, etc.\n",
    "2. In order to create even more training data, we can make the splits random, i.e., start at random positions in the data and return the next 150,000 data points. This way, the 'cuts' are not made at fixed positions, which might help against overfitting as well.\n",
    "\n",
    "Let's try the second approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_train_sequence(data, size=150000):\n",
    "    while True:\n",
    "        idx = np.random.randint(0, len(data))\n",
    "        yield data[idx:idx+size]\n",
    "\n",
    "train_gen = generate_train_sequence(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can generate as many training sequences as you want. For illustration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 5  # make this bigger of course\n",
    "for i in range(n_samples):\n",
    "    sample = next(train_gen)\n",
    "    # ...do training on sample or store it...\n",
    "    print(sample.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Secondly, for every sequence of 150,000 obervations, we need to only return one prediction, which should match the time remaining to the earthquake at the __end of the sequence__.\n",
    "Let's make sure this is what we return, instead of just a slice of the DataFrame. Note: Here we also improve the speed by only calling `np.random.randint()` once every 10,000 indices (there is significant overhead in making that call)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_generator(data, xcol=\"acoustic_data\", ycol=\"time_remaining\", size=150000):\n",
    "    \"\"\"Generator that extracts segments of the signal from the data.\"\"\"\n",
    "    while True:\n",
    "        indices = np.random.randint(0, len(data) - size - 1, 10000)\n",
    "        for idx in indices:\n",
    "            y = data[ycol].iloc[idx + size - 1]\n",
    "            x = data[idx:(idx + size)][xcol].values\n",
    "            yield x, y\n",
    "\n",
    "train_gen = sequence_generator(train, xcol=xcol, ycol=ycol, size=150000)\n",
    "for i in range(5):\n",
    "    sample_x, sample_y = next(train_gen)\n",
    "    print(\"sample length: {}, prediction: {}\".format(len(sample_x), sample_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can create random datasets or batches of samples to train models on. However, storing the 150,000 observations for every training sample is gonna lead to problems. Hence, it is better to first compute features on the generated samples, and store only the computed features.\n",
    "\n",
    "Let's create a simple class that computes features and apply it to randomly sampled sequences of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureComputer():\n",
    "\n",
    "    feats = [\"minimum\", \"maximum\", \"mean\", \"median\", \"std\"]\n",
    "\n",
    "    def __init__(self, minimum=True, maximum=True, mean=True, median=True, std=True, quantiles=None, verbose=True):\n",
    "        self.minimum = minimum\n",
    "        self.maximum = maximum\n",
    "        self.mean = mean\n",
    "        self.median = median\n",
    "        self.std = std\n",
    "        self.quantiles = quantiles\n",
    "        \n",
    "        self.feature_names = self._infer_names()\n",
    "        self.n_features = np.sum([minimum, maximum, mean, median, std, len(quantiles)])\n",
    "        self.result_template = np.zeros(self.n_features)\n",
    "\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def _infer_names(self):\n",
    "        quantile_names = [str(q) + \"-quantile\" for q in self.quantiles]\n",
    "        i = 0\n",
    "        names = np.array(self.feats)[[self.minimum, self.maximum, self.mean, self.median, self.std]]\n",
    "        names = names.tolist() + quantile_names\n",
    "        return names\n",
    "        \n",
    "    def compute(self, arr):\n",
    "        result = np.zeros_like(self.result_template)\n",
    "        i = 0\n",
    "        if self.minimum:\n",
    "            result[i] = np.min(arr)\n",
    "            i += 1\n",
    "        if self.maximum:\n",
    "            result[i] = np.max(arr)\n",
    "            i += 1\n",
    "        if self.mean:\n",
    "            result[i] = np.mean(arr)\n",
    "            i += 1\n",
    "        if self.median:\n",
    "            result[i] = np.median(arr)\n",
    "            i += 1\n",
    "        if self.std:\n",
    "            result[i] = np.std(arr)\n",
    "            i += 1\n",
    "        if self.quantiles is not None:\n",
    "            result[i:] = np.quantile(arr, q=self.quantiles)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "computer = FeatureComputer(quantiles=[0.0025, 0.005, 0.01, 0.02, 0.05, 0.95, 0.98, 0.99, 0.995, 0.9975])\n",
    "feat_names = computer.feature_names\n",
    "\n",
    "for i in range(2):\n",
    "    sample_x, sample_y = next(train_gen)\n",
    "    sample_features = computer.compute(sample_x)\n",
    "    print([feat_names[i] + \": {}\".format(sample_features[i]) for i in range(len(sample_features))])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This way, we can create a new dataset with several features and as much samples as we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_dataset(data, feature_computer, xcol=\"acoustic_data\", ycol=\"time_to_failure\", n_samples=100):\n",
    "    \n",
    "    new_data = pd.DataFrame({feature: np.zeros(n_samples) for feature in feature_computer.feature_names})\n",
    "    targets = np.zeros(n_samples)\n",
    "    data_gen = sequence_generator(train, xcol=xcol, ycol=ycol, size=150000)\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        x, y = next(data_gen)\n",
    "        new_data.iloc[i, :] = feature_computer.compute(x)\n",
    "        targets[i] = y\n",
    "\n",
    "    new_data[ycol] = targets\n",
    "    return new_data\n",
    "\n",
    "generated_train = create_feature_dataset(train, computer, n_samples=10)\n",
    "generated_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if this works okay timewise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import timeit\n",
    "\n",
    "def time_sampling():\n",
    "    create_feature_dataset(train, computer, n_samples=1000)\n",
    "\n",
    "avg_time = timeit(time_sampling, number=5) / 5\n",
    "print(\"It takes about {:.2f} seconds to sample and process 1000 sequences. \"\n",
    "      \"Note that this is 150 million observations ({:.2f}% of the dataset).\"\n",
    "      .format(avg_time, 150e6/train.shape[0]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Adding Cross-Validation\n",
    "However, we cannot sample validation sequences from the same dataset as the training samples, since there might be overlap (data leakage) in the sampled sequences. Hence, we need to split first. Note that the data should remain in the same order when we split; we should not shuffle, because then we destroy the time series.\n",
    "\n",
    "Let's create a simple cross validation framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import time # for loggin progress\n",
    "\n",
    "\n",
    "# helper function to print progress with time stamp\n",
    "def progress(text, verbose=True, same_line=False, newline_end=True):\n",
    "    if verbose:\n",
    "        print(\"{}[{}] {}\".format(\"\\r\" if same_line else \"\", time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "                                 text), end=\"\\n\" if newline_end else \"\")\n",
    "\n",
    "\n",
    "def train_and_predict(train_x, train_y, val_x, model_cls, **model_params):\n",
    "    model = model_cls(**model_params)\n",
    "    model.fit(train_x, train_y)\n",
    "    predictions = model.predict(val_x)\n",
    "    return predictions\n",
    "\n",
    "\n",
    "def cross_validate(data, model_cls, feature_computer, ycol=\"time_to_failure\", n_splits=5, \n",
    "                   train_samples=1000, val_samples=500, **model_params):\n",
    "    \"\"\"Perform custom cross validation using randomly sequences of observations.\"\"\"\n",
    "    splitter = KFold(n_splits=n_splits, shuffle=False)\n",
    "\n",
    "    scores = []\n",
    "    for i, (train_index, val_index) in enumerate(splitter.split(data)):\n",
    "        progress(\"Starting cross-validation fold {}.\".format(i))\n",
    "\n",
    "        # split the data according to the indices\n",
    "        progress(\"Splitting data in train and validation sets.\")\n",
    "        train = data.iloc[train_index]\n",
    "        val = data.iloc[val_index]\n",
    "\n",
    "        # sample random sequences for training\n",
    "        progress(\"Sampling {} sequences from training data.\".format(train_samples))\n",
    "        train_features = create_feature_dataset(train, feature_computer, n_samples=train_samples)\n",
    "        y_train = train_features[ycol]\n",
    "        x_train = train_features.drop(ycol, axis=1)\n",
    "        progress(\"Train set sampled.\")\n",
    "\n",
    "        # sample random sequences for validation\n",
    "        progress(\"Sampling {} sequences from validation data.\".format(val_samples))\n",
    "        val_features = create_feature_dataset(val, feature_computer, n_samples=val_samples)\n",
    "        y_val = val_features[ycol]\n",
    "        x_val = val_features.drop(ycol, axis=1)\n",
    "        progress(\"Validation set sampled.\")\n",
    "\n",
    "        # train and predict validation set\n",
    "        progress(\"Start training and predicting.\")\n",
    "        y_val_hat = train_and_predict(x_train, y_train, x_val, model_cls, **model_params)\n",
    "        progress(\"Predictions on validation set made.\")\n",
    "        \n",
    "        # evaluate using mean absolute error for this competition\n",
    "        score = mean_absolute_error(y_val, y_val_hat)\n",
    "        scores.append(score)\n",
    "        progress(\"Validation score: {}.\".format(score))\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform Cross Validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"n_estimators\": 1000,\n",
    "    \"criterion\": 'mae',\n",
    "    \"n_jobs\": -1,\n",
    "    \"verbose\": 1,\n",
    "}\n",
    "\n",
    "scores = cross_validate(train, RandomForestRegressor, computer, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean validation score: {}\".format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train the model on a bunch of samples from the entire training data and predict the test to see whether the leaderboard and cross validation score are similar. So no blending or stacking for now.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_on_test(model, feature_computer, ycol=\"time_to_failure\", data_dir=data_dir):\n",
    "\n",
    "    # take the segment ids from the sample submission file\n",
    "    sample_submission = pd.read_csv(os.path.join(data_dir, \"sample_submission.csv\"), index_col=\"seg_id\")\n",
    "    x_test = pd.DataFrame(columns=feature_computer.feature_names, dtype=np.float64, index=sample_submission.index)\n",
    "\n",
    "    # load and predict segments one by one\n",
    "    for i, seg_id in enumerate(x_test.index):\n",
    "        progress(\"Loading and computing features for segment {}/{}.\".format(i + 1, len(x_test)),\n",
    "                 same_line=True, newline_end=(i + 1 == len(x_test)))\n",
    "\n",
    "        segment = pd.read_csv(os.path.join(data_dir, \"test\", seg_id + \".csv\"))\n",
    "        x_test.loc[seg_id, :] = feature_computer.compute(np.array(segment))\n",
    "\n",
    "    sample_submission[ycol] = model.predict(x_test)\n",
    "    progress(\"Predictions made.\")\n",
    "    return sample_submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(**params)\n",
    "\n",
    "progress(\"Creating dataset of 5000 training samples.\")\n",
    "train_features = create_feature_dataset(train, computer, n_samples=5000)\n",
    "\n",
    "progress(\"Fitting RandomForestRegressor on data.\")\n",
    "model.fit(train_features.drop(ycol, axis=1), train_features[ycol])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And predict on the train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progress(\"Loading and predicting test data.\")\n",
    "submission = predict_on_test(model, computer)\n",
    "submission.reset_index().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.reset_index().to_csv(os.path.join(data_dir, \"first_submission.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Leaderboard score: 1.758 (place 868 / 1200 at time of submitting).__\n",
    "Score is better than CV score of 2.2. This may be due to the fact that we have actual earthquakes in the training (and thus validation) data and not in the test data.\n",
    "\n",
    "Ways of improvement:\n",
    "- Remove observations around earthquakes from the training data to better resemble the test data.\n",
    "- Calculate more features:\n",
    "    - calculate features over subsequences of a 150k sequence, e.g., calc features for every 15k observations, so that we have timely information.\n",
    "    - calculate more typical signal processing features, e.g., Fourier Transforms and stuff..\n",
    "    - other features...\n",
    "    - Use RNNs to learn features from the raw signal.\n",
    "- We are underfitting: use more complex models.\n",
    "- Tune the model(s).\n",
    "- Use blending (or stacking but blending is easier and works better for this competition according to some kernel).\n",
    "- Fix random seeds to get more stable output (since now we have a different dataset at every run)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
